import urllib.request
import urllib.parse
import os  #创建文件夹

url='http://tieba.baidu.com/f?ie=utf-8'
ba_name=input('输入吧名：')
start_page=int(input('起始页码：'))
end_page=int(input('结束页码：'))
#创建文件夹
if not os.path.exists(ba_name):
	os.mkdir(ba_name)
#循环，一次爬取每一页
for page in range(start_page,end_page+1):
	#page就是当前页，拼接url的过程
	data={
	   'kw':ba_name,
	   'pn':(page - 1)*50
}
data=urllib.parse.urlencode(data)
 #生成指定的url
url_t=url+data
 #print(url-t)
headers={
       'user-agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'
}
request=urllib.request.Request(url=url_t,headers=headers)
print('第%s页开始下载.....' % start_page)
response=urllib.request.urlopen(request)
#生成文件名
filename=ba_name+'_'+str(page)+'.html'
#拼接文件路径
filepath=ba_name+'/'+filename
#写内容
with open(filepath,'wb') as fp:
	fp.write(response.read())
print('第%s页停止下载....' % end_page)
